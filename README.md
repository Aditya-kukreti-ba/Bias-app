# âš–ï¸ Bias Auditor â€” Risk Score Fairness Dashboard

> **Live Demo:** [https://bias-app.vercel.app/](https://bias-app.vercel.app/)

A full-stack interactive dashboard for detecting and visualizing bias in AI risk scoring models. Audit your model's fairness across **race/ethnicity**, **gender**, and **age group** dimensions using industry-standard bias metrics â€” powered by an AI analysis engine built on **Llama 3.3 70B via Groq**.

---

## ğŸ“¸ Preview

![Bias Auditor Dashboard](https://bias-app.vercel.app/og-preview.png)

---

## âœ¨ Features

- ğŸ“Š **Disparate Impact Analysis** â€” Flags groups using the 4/5ths rule (DI < 0.8 or > 1.25 = discriminatory)
- ğŸ“‰ **Error Rate Disparity** â€” False positive and false negative rates broken down by demographic group
- ğŸ”¥ **Score Heatmap** â€” Average risk scores at the Race Ã— Gender intersection
- ğŸ•¸ï¸ **Fairness Radar Chart** â€” Multi-metric group comparison in one view
- ğŸ¤– **AI Bias Audit** â€” One-click plain-language interpretation of all bias metrics using Llama 3.3 70B
- ğŸ“ **CSV Upload** â€” Drop in your own dataset for instant analysis
- ğŸ² **Synthetic Data Generator** â€” Built-in data generation (100â€“2000 records) with intentional bias patterns for testing
- ğŸ“± **Fully Responsive** â€” Works on desktop, tablet, and mobile

---

## ğŸš€ Getting Started

### Prerequisites
- Node.js 18+
- A free [Groq API key](https://console.groq.com)

### Installation

```bash
# 1. Clone the repository
git clone https://github.com/Aditya-kukreti-ba/Bias-app.git
cd Bias-app

# 2. Install dependencies
npm install

# 3. Create environment file
echo "VITE_GROQ_API_KEY=your_groq_key_here" > .env

# 4. Start the dev server
npm run dev
```

Open [http://localhost:5173](http://localhost:5173) in your browser.

---

## ğŸ§ª Testing with Sample Data

A ready-made CSV file is included for testing. It contains 200 records with intentionally embedded bias patterns across all demographic groups.

**Required CSV columns:**

| Column | Values |
|--------|--------|
| `race` | White, Black, Hispanic, Asian, Other |
| `gender` | Male, Female, Non-binary |
| `ageGroup` | 18-25, 26-35, 36-50, 51-65, 65+ |
| `riskScore` | 0â€“100 |

Upload it via the **ğŸ“ Upload CSV** button in the dashboard.

---

## ğŸ“ Bias Metrics Explained

| Metric | Description | Threshold |
|--------|-------------|-----------|
| **Disparate Impact (DI)** | Ratio of high-risk flagging rates between groups | ğŸŸ¢ 0.8â€“1.25 = Fair Â· ğŸŸ¡ Borderline Â· ğŸ”´ Discriminatory |
| **False Positive Rate (FPR)** | Rate of incorrectly flagging low-risk individuals as high-risk | Lower is better |
| **False Negative Rate (FNR)** | Rate of missing truly high-risk individuals | Lower is better |
| **Average Risk Score** | Mean score per demographic group | Should be similar across groups |

---

## ğŸ› ï¸ Tech Stack

| Layer | Technology |
|-------|-----------|
| Framework | React + Vite |
| Charts | Recharts |
| AI Engine | Llama 3.3 70B via Groq API (free) |
| Styling | Inline CSS with warm editorial theme |
| Fonts | Playfair Display + DM Sans |
| Deployment | Vercel |

---

## ğŸŒ Deployment on Vercel

1. Push your code to GitHub
2. Import the repo at [vercel.com](https://vercel.com)
3. Add environment variable in Vercel dashboard:
   - **Key:** `VITE_GROQ_API_KEY`
   - **Value:** your Groq API key
4. Deploy â€” done!

---

## âš ï¸ Security Notes

- Never hardcode API keys in your source code
- The `.env` file is git-ignored and stays local
- Groq API key is injected at build time via `import.meta.env.VITE_GROQ_API_KEY`
- For production apps, route API calls through a backend server

---

## ğŸ“„ License

MIT License â€” free to use, modify, and distribute.

---

## ğŸ™Œ Acknowledgements

- [Groq](https://groq.com) for the free, blazing-fast LLM API
- [Recharts](https://recharts.org) for the charting library
- [Vercel](https://vercel.com) for free hosting

---

<p align="center">Built with â¤ï¸ Â· <a href="https://bias-app.vercel.app/">Live Demo</a></p>
